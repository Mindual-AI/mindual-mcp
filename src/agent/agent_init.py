# src/agent/agent_init.py
# Gemini ê¸°ë°˜ ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ë° ì§ˆì˜ ì²˜ë¦¬

from typing import Dict, Any, List
import time

import google.generativeai as genai

from src.config import GEMINI_API_KEY, GEMINI_MODEL_ID
from src.agent.system_prompt import SYSTEM_PROMPT
from src.agent.mcp_tools import search_manual, lookup_trouble, propose_next_action

from src.parse.parse_text import extract_reminder
from src.agent.calendar_client import create_reminder_event


# ---------- Gemini ì´ˆê¸°í™” ----------

if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)

_model = genai.GenerativeModel(GEMINI_MODEL_ID) if GEMINI_API_KEY else None

def _call_gemini(prompt: str) -> str:
    """
    Gemini í˜¸ì¶œ ë˜í¼: ë¡œê·¸ì™€ ê°„ë‹¨í•œ íƒ€ì„ ê³„ì¸¡ë§Œ ì¶”ê°€
    """
    if _model is None:
        # ì•ˆì „ì¥ì¹˜: ëª¨ë¸ì´ ì—†ì„ ë•ŒëŠ” ë°”ë¡œ ë¦¬í„´
        print("[Gemini] _model is None, skip LLM call")
        return "LLMì´ ì„¤ì •ë˜ì–´ ìˆì§€ ì•Šì•„, ê²€ìƒ‰ëœ ë§¤ë‰´ì–¼ ë‚´ìš©ì„ ê·¸ëŒ€ë¡œ ì°¸ê³ í•´ ì£¼ì„¸ìš”."

    print("[Gemini] call start")
    t0 = time.time()

    # ğŸ’¡ ì•„ì£¼ ê±°ì¹œ íƒ€ì„ì•„ì›ƒ: 30ì´ˆ ì´ìƒ ê±¸ë¦¬ë©´ ì˜ˆì™¸ ë˜ì§€ê¸°
    #   SDK ìì²´ íƒ€ì„ì•„ì›ƒì´ ì—†ì–´ì„œ ë¬´í•œ ëŒ€ê¸°í•˜ë©´, ì—¬ê¸°ì„œë¼ë„ ëŠì–´ì£¼ìëŠ” ëŠë‚Œ
    try:
        resp = _model.generate_content(
            prompt,
        )
    except Exception as e:
        print("[Gemini] exception:", repr(e))
        raise

    dt = time.time() - t0
    print(f"[Gemini] call end, {dt:.2f}s")

    text = getattr(resp, "text", None)
    if not text and getattr(resp, "candidates", None):
        try:
            text = resp.candidates[0].content.parts[0].text
        except Exception:
            text = None

    return text or "Gemini ì‘ë‹µì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤."
# ---------- í—¬í¼: ê²€ìƒ‰ ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´ êµ¬ì„± ----------

def _build_context(query: str, hits: List[Dict[str, Any]]) -> str:
    """
    FAISS / manual ê²€ìƒ‰ ê²°ê³¼(hits)ë¥¼ ì‚¬ëŒì´ ì½ê¸° ì¢‹ì€ ë¬¸ìì—´ë¡œ ë³€í™˜.
    hits: [{ "content": ..., "page": ..., ... }, ...]
    """
    if not hits:
        return "ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ."

    lines: List[str] = []
    for i, h in enumerate(hits, 1):
        prefix = f"[{i}] (page {h.get('page', '?')})"
        content = h.get("content", "")
        lines.append(f"{prefix}\n{content}\n")

    return "\n".join(lines)


# ---------- ë©”ì¸ ì—”íŠ¸ë¦¬: answer_query ----------

def answer_query(payload: Dict[str, Any]) -> Dict[str, Any]:
    print(">>> answer_query called with:", payload, flush=True)
    """
    payload = {
      "query": "...",            # ì‚¬ìš©ìì˜ ìì—°ì–´ ì§ˆë¬¸
      "device_state": {...},     # ì„ íƒ: í˜„ì¬ ë””ë°”ì´ìŠ¤ ìƒíƒœ ì •ë³´
      "error_code": "E05"        # ì„ íƒ: ì˜¤ë¥˜ ì½”ë“œ
    }

    ë°˜í™˜:
    {
      "answer": str,       # LLM ë˜ëŠ” ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì‘ë‹µ
      "proactive": str?,   # ëŠ¥ë™ ì œì•ˆ í…ìŠ¤íŠ¸(ìˆë‹¤ë©´)
      "trouble": str?,     # ì˜¤ë¥˜ ì½”ë“œ ì„¤ëª…(ìˆë‹¤ë©´)
      "used_llm": bool     # LLM ì‚¬ìš© ì—¬ë¶€
    }
    """

    query = (payload.get("query") or "").strip()
    device_state = payload.get("device_state") or {}
    error_code = payload.get("error_code")

    # âœ… 0) ìì—°ì–´ ë¦¬ë§ˆì¸ë“œ â†’ Google Calendar ì¼ì • ìƒì„±
    reminder = extract_reminder(query) if query else None
    if reminder:
        print("[REMINDER] create event:", reminder.summary, reminder.start, reminder.end)
        event_id, link = create_reminder_event(
            summary=reminder.title,
            start=reminder.start_dt,
        )

        # ì‚¬ëŒ ëˆˆì— ìì—°ìŠ¤ëŸ½ê²Œ ë³´ì´ëŠ” ì‹œê°„ í¬ë§·
        pretty_time = reminder.start_dt.strftime("%mì›” %dì¼ %p %Iì‹œ").replace("AM", "ì˜¤ì „").replace("PM", "ì˜¤í›„")

        msg = f"{pretty_time} '{reminder.title}' ì¼ì •ì´ Google Calendarì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤."
        if link:
            msg += f"\n(ìº˜ë¦°ë”ì—ì„œ ë³´ê¸°: {link})"

        return {
            "answer": msg,
            "proactive": None,
            "trouble": None,
            "used_llm": False,
            "calendar_event_id": event_id,
        }

    # 1) ëŠ¥ë™ ì œì•ˆ (ê°„ë‹¨ ê·œì¹™ ê¸°ë°˜)
    proactive: str | None = propose_next_action(device_state) if device_state else None

    # 2) ì˜¤ë¥˜ ì½”ë“œê°€ ìˆìœ¼ë©´ ê´€ë ¨ íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ë¨¼ì € ì¡°íšŒ
    trouble_txt: str | None = None
    if error_code:
        t = lookup_trouble(error_code)
        if t:
            trouble_txt = (
                f"[{error_code}] ì¦ìƒ: {t.get('symptom', '')}\n"
                f"ì›ì¸: {t.get('cause', '')}"
            )

    # 3) ë§¤ë‰´ì–¼ ê²€ìƒ‰: ì§ˆë¬¸ì´ ìˆìœ¼ë©´ ì§ˆë¬¸ìœ¼ë¡œ, ì—†ìœ¼ë©´ ì˜¤ë¥˜ì½”ë“œ/ê¸°ë³¸ ì‚¬ìš©ìœ¼ë¡œ
    search_query = query if query else (error_code or "ê¸°ë³¸ ì‚¬ìš©")
    hits = search_manual(search_query)
    context_txt = _build_context(search_query, hits)

    # 4) LLMì´ ì—†ëŠ” ê²½ìš°: ê²€ìƒ‰ ê²°ê³¼ë§Œ ê·¸ëŒ€ë¡œ ë°˜í™˜
    if not _model:
        return {
            "answer": context_txt,
            "proactive": proactive,
            "trouble": trouble_txt,
            "used_llm": False,
        }

    # 5) í”„ë¡¬í”„íŠ¸ êµ¬ì„± (f-string ëŒ€ì‹  ë¦¬ìŠ¤íŠ¸ë¡œ ì•ˆì „í•˜ê²Œ ì¡°ë¦½)
    prompt_parts: List[str] = []

    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
    prompt_parts.append(SYSTEM_PROMPT)
    prompt_parts.append("")  # ë¹ˆ ì¤„

    # ì‚¬ìš©ì ì§ˆë¬¸
    prompt_parts.append("ì‚¬ìš©ì ì§ˆë¬¸:")
    prompt_parts.append(query or error_code or "ì§ˆë¬¸ ì—†ìŒ")
    prompt_parts.append("")

    # ê²€ìƒ‰ ì»¨í…ìŠ¤íŠ¸
    prompt_parts.append("ê²€ìƒ‰ ì»¨í…ìŠ¤íŠ¸(ë§¤ë‰´ì–¼ ë°œì·Œ):")
    prompt_parts.append(context_txt)
    prompt_parts.append("")

    # ì˜¤ë¥˜ ì½”ë“œ ì •ë³´
    if trouble_txt:
        prompt_parts.append("ì˜¤ë¥˜ì½”ë“œ ì •ë³´:")
        prompt_parts.append(trouble_txt)
        prompt_parts.append("")

    # ëŠ¥ë™ ì œì•ˆ
    if proactive:
        prompt_parts.append("ëŠ¥ë™ ì œì•ˆ í›„ë³´:")
        prompt_parts.append(proactive)
        prompt_parts.append("")

    # ì¶œë ¥ í˜•ì‹ ê°€ì´ë“œ
    prompt_parts.append(
        "ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ë‹¨ê³„í˜•ìœ¼ë¡œ ê°„ê²°íˆ ë‹µë³€í•´ë¼. "
        "ê²½ê³ ê°€ ìˆìœ¼ë©´ ìµœìƒë‹¨ì— 'âš ï¸ ì£¼ì˜'ë¡œ ê°•ì¡°í•´ë¼."
    )

    prompt = "\n".join(prompt_parts)

    # 6) Gemini í˜¸ì¶œ
    resp = _model.generate_content(prompt)
    answer_text = getattr(resp, "text", None) or "ì‘ë‹µ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."

    return {
        "answer": answer_text,
        "proactive": proactive,
        "trouble": trouble_txt,
        "used_llm": True,
    }
