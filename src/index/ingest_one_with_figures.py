# scripts/ingest_one_with_figures.py
"""
PDF 1ê°œë¥¼ íŽ˜ì´ì§€ ì´ë¯¸ì§€ë¡œ ë Œë” â†’ Gemini Flashë¡œ OCR â†’ í…ìŠ¤íŠ¸/íŽ˜ì´ì§€/ë„í•´bbox ë©”íƒ€ë¥¼ DBì— ì ìž¬.
* íŽ˜ì´ì§€ í¬ë¡­(ë„í•´ ì´ë¯¸ì§€) ì €ìž¥ ì—†ìŒ. (figures.pathì—ëŠ” íŽ˜ì´ì§€ ì´ë¯¸ì§€ ê²½ë¡œ ì €ìž¥)
* RAG ì‘ë‹µ ì‹œ í•´ë‹¹ íŽ˜ì´ì§€ ì´ë¯¸ì§€ë¥¼ ê·¸ëŒ€ë¡œ ë³´ì—¬ì¤„ ìˆ˜ ìžˆë„ë¡ page_images/figures/chunksë¥¼ ì±„ì›€.
"""

from __future__ import annotations
import argparse, json, os, random, re, sqlite3, time, sys
from pathlib import Path
from typing import Dict, List, Optional, Tuple

import fitz  # PyMuPDF
from PIL import Image
import google.generativeai as genai

# --- import path bootstrap ---
ROOT = Path(__file__).resolve().parents[2]
SRC  = ROOT / "src"
DBP  = ROOT / "db"
for p in (str(ROOT), str(SRC), str(DBP)):
    if p not in sys.path:
        sys.path.insert(0, p)

def _import_config():
    for name in ("src.config", "config"):
        try:
            mod = __import__(name, fromlist=["*"])
            return mod
        except ModuleNotFoundError:
            continue
    raise

def _import_upsert():
    """
    upsert ëª¨ë“ˆì„ ì—¬ëŸ¬ ê²½ë¡œ í›„ë³´ì—ì„œ import.
    - db/upsert.py  â†’ "db.upsert"
    - src/db/upsert.py â†’ "src.db.upsert"
    - ë£¨íŠ¸/upsert.py â†’ "upsert"
    """
    candidates = ("db.upsert", "src.db.upsert", "upsert")
    last_err = None

    for name in candidates:
        try:
            mod = __import__(name, fromlist=["*"])
            print(f"[debug] loaded upsert module: {name}")
            return mod
        except ModuleNotFoundError as e:
            last_err = e
            continue

    raise RuntimeError(
        "upsert ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. db/upsert.py ìœ„ì¹˜ì™€ __init__.py ì—¬ë¶€ë¥¼ í™•ì¸í•˜ì„¸ìš”."
    ) from last_err

_cfg = _import_config()
_up  = _import_upsert()
GEMINI_API_KEY  = getattr(_cfg, "GEMINI_API_KEY")
GEMINI_MODEL_ID = getattr(_cfg, "GEMINI_MODEL_ID", "gemini-2.0-flash")
DB_PATH         = getattr(_cfg, "DB_PATH", "./manuals.sqlite")

upsert_manual = getattr(_up, "upsert_manual")
insert_chunk  = getattr(_up, "insert_chunk")

DEFAULT_PER_PAGE_SLEEP = 1.0

# ---------- utils ----------
def ensure_dir(p: Path):
    p.mkdir(parents=True, exist_ok=True)

def setup_gemini():
    if not GEMINI_API_KEY:
        raise RuntimeError("GEMINI_API_KEY not set. Put it in .env")
    genai.configure(api_key=GEMINI_API_KEY)
    return genai.GenerativeModel(GEMINI_MODEL_ID)

def retry_with_backoff(fn, *, retries=6, base=1.5, jitter=0.3, on_msg=""):
    for attempt in range(retries):
        try:
            return fn()
        except Exception as e:
            msg = str(e)
            if "Resource exhausted" in msg or "429" in msg or "exceeded" in msg:
                sleep = (base ** attempt) + random.uniform(0, jitter)
                print(f"â³ {on_msg} ìž¬ì‹œë„ {attempt+1}/{retries} ... {sleep:.1f}s ëŒ€ê¸° (ì‚¬ìœ : {msg[:80]}...)")
                time.sleep(sleep); continue
            raise
    raise RuntimeError(f"ìž¬ì‹œë„ ì´ˆê³¼: {on_msg}")

def gemini_ocr(model, image: Image.Image) -> str:
    prompt = (
        "ì´ ì´ë¯¸ì§€ëŠ” ì „ìžê¸°ê¸° ì‚¬ìš©ì„¤ëª…ì„œì˜ í•œ íŽ˜ì´ì§€ìž…ë‹ˆë‹¤. "
        "ë³´ì´ëŠ” ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ê°€ëŠ¥í•œ ì •í™•ë„ë¡œ ì¶”ì¶œí•´ ì£¼ì„¸ìš”. "
        "ì¤„ë°”ê¿ˆê³¼ ë¦¬ìŠ¤íŠ¸, í‘œ êµ¬ì¡°(ê°€ëŠ¥í•˜ë©´ ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸”)ë¥¼ ë³´ì¡´í•´ ì£¼ì„¸ìš”."
    )
    def _call():
        return model.generate_content([prompt, image])
    resp = retry_with_backoff(_call, on_msg="Gemini OCR")
    return resp.text or ""

def infer_meta_from_filename(stem: str):
    tokens = re.split(r"[^A-Za-z0-9\-]+", stem)
    models = [t for t in tokens if re.search(r"[A-Za-z]{2,}\d{2,}", t)]
    m = re.search(r"(20\d{2}-\d{2}-\d{2})", stem)
    created_at = m.group(1) if m else ""
    return list(dict.fromkeys(models)), created_at

def ensure_fts_sync(conn: sqlite3.Connection):
    conn.execute("""
        INSERT INTO chunks_fts(rowid, content)
        SELECT id, content FROM chunks
        WHERE id NOT IN (SELECT rowid FROM chunks_fts);
    """)
    conn.commit()

# ---------- figure detection (bbox only; no crop saved) ----------
def detect_figures(page: fitz.Page, min_area_pdf: float = 10_000.0) -> List[Tuple[float, float, float, float]]:
    """
    PyMuPDF í…ìŠ¤íŠ¸ dictì—ì„œ type=1 ì´ë¯¸ì§€ ë¸”ë¡ bbox(PDF ì¢Œí‘œ)ë¥¼ ìˆ˜ì§‘.
    (ìŠ¤ìº” PDFì˜ ê²½ìš° íŽ˜ì´ì§€ ì „ì²´ 1ê°œë§Œ ë‚˜ì˜¬ ìˆ˜ ìžˆìŒ. ê·¸ ì™¸ ë²¡í„° ë„í•´ëŠ” ë³„ë„ ê³ ë„í™” ê°€ëŠ¥)
    """
    page_dict = page.get_text("dict")
    boxes = []
    for b in page_dict.get("blocks", []):
        if b.get("type") != 1:
            continue
        x0, y0, x1, y1 = b["bbox"]
        if (x1 - x0) * (y1 - y0) >= min_area_pdf:
            boxes.append((x0, y0, x1, y1))
    return boxes

def px_bbox_from_pdf_bbox(pdf_bbox: Tuple[float, float, float, float], page: fitz.Page, dpi: int):
    x0, y0, x1, y1 = pdf_bbox
    zoom = dpi / 72.0
    mat = fitz.Matrix(zoom, zoom)
    r = fitz.Rect(x0, y0, x1, y1) * mat
    return (int(round(r.x0)), int(round(r.y0)), int(round(r.x1)), int(round(r.y1)))

def detect_nearby_caption(page: fitz.Page,
                          pdf_bbox: Tuple[float, float, float, float],
                          max_vertical_gap: float = 100.0) -> Optional[str]:
    x0, y0, x1, y1 = pdf_bbox
    page_dict = page.get_text("dict")
    best = ""
    for block in page_dict.get("blocks", []):
        if block.get("type") != 0:
            continue
        bx0, by0, bx1, by1 = block["bbox"]
        horizontally_overlaps = not (bx1 < x0 or bx0 > x1)
        is_below = by0 >= y1 and (by0 - y1) <= max_vertical_gap
        if horizontally_overlaps and is_below:
            lines = []
            for ln in block.get("lines", []):
                spans = [sp.get("text", "") for sp in ln.get("spans", [])]
                line = "".join(spans).strip()
                if line:
                    lines.append(line)
            cand = "\n".join(lines).strip()
            if len(cand) > len(best):
                best = cand
    return best or None

# ---------- main pipeline ----------
def ingest_one_with_figures(pdf_path: Path,
                            brand: str,
                            language: str,
                            title: str,
                            dpi: int = 300,
                            min_area: float = 10_000.0,
                            per_page_sleep: float = DEFAULT_PER_PAGE_SLEEP):
    stem = pdf_path.stem
    processed_dir = Path("data/processed") / stem
    ensure_dir(processed_dir)

    model = setup_gemini()
    doc = fitz.open(str(pdf_path))

    models, created_at = infer_meta_from_filename(stem)
    manual_id = upsert_manual(
        file_name=pdf_path.name,
        model_list=models or [],
        language=language,
        title=title or stem,
        created_at=created_at or ""
    )
    print(f"âœ… Upserted manual id={manual_id} models={models} created_at={created_at}")

    conn = sqlite3.connect(DB_PATH, timeout=10)
    merged_parts: List[str] = []

    for i, page in enumerate(doc, start=1):
        # 1) íŽ˜ì´ì§€ ë Œë” â†’ jpg ì €ìž¥
        page_jpg = processed_dir / f"page_{i}.jpg"
        pix = page.get_pixmap(dpi=dpi)
        pix.save(str(page_jpg))

        # page_images í…Œì´ë¸”ì—ëŠ” ingest ì´í›„ ë³„ë„ ë·°ì—ì„œ ì“°ê¸° ì¢‹ê²Œ ë“±ë¡
        conn.execute(
            """
            INSERT INTO page_images(manual_id, page, path)
            VALUES(?,?,?)
            ON CONFLICT(manual_id, page) DO UPDATE SET path=excluded.path
            """,
            (manual_id, i, str(page_jpg)),
        )
        conn.commit()

        # 2) OCR (Gemini)
        image = Image.open(page_jpg)
        text = gemini_ocr(model, image)
        if text.strip():
            insert_chunk(manual_id=manual_id, section_id=None, page=i,
                         content=text.strip(), meta={"source": "ocr", "dpi": dpi})
            merged_parts.append(text.strip())

        # 3) ë„í•´ bboxë§Œ ê¸°ë¡(í¬ë¡­ ì €ìž¥ ì•ˆ í•¨) â€” figures.pathëŠ” íŽ˜ì´ì§€ ì´ë¯¸ì§€ ê²½ë¡œë¡œ ì €ìž¥
        fig_boxes = detect_figures(page, min_area_pdf=min_area) or []
        for fi, box_pdf in enumerate(fig_boxes):
            bbox_px = px_bbox_from_pdf_bbox(box_pdf, page, dpi)
            caption = detect_nearby_caption(page, box_pdf)
            conn.execute(
                """INSERT INTO figures(manual_id,page,bbox_pdf,bbox_px,path,thumb_path,caption,ocr,meta)
                   VALUES(?,?,?,?,?,?,?,?,?)""",
                (
                    manual_id,
                    i,
                    json.dumps(list(box_pdf), ensure_ascii=False),
                    json.dumps(list(bbox_px), ensure_ascii=False),
                    str(page_jpg),   # â† í¬ë¡­ ëŒ€ì‹  íŽ˜ì´ì§€ ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì €ìž¥
                    None,            # thumb ì—†ìŒ
                    caption or None,
                    None,            # ì¶”í›„ í•„ìš” ì‹œ ê·¸ë¦¼ ë‚´ OCR
                    json.dumps({"detector": "pymupdf_image_block", "dpi": dpi}, ensure_ascii=False),
                ),
            )

        conn.commit()
        print(f"ðŸ“„ Page {i}: OCR {len(text)} chars, {len(fig_boxes)} figure-bboxes")
        if per_page_sleep > 0:
            time.sleep(per_page_sleep)

    # 4) ë¨¸ì§€ í…ìŠ¤íŠ¸, FTS ë™ê¸°í™”
    merged_path = processed_dir / "merged_manual.txt"
    merged_path.write_text("\n\n".join(merged_parts), encoding="utf-8")
    ensure_fts_sync(conn)
    conn.close()
    print(f"âœ… Merged text -> {merged_path}\nðŸŽ‰ Ingestion complete. DB: {DB_PATH}")

# ---------- CLI ----------
def main():
    ap = argparse.ArgumentParser(description="Ingest one manual PDF (no-crop; store page & figure bbox meta)")
    ap.add_argument("--pdf", required=True)
    ap.add_argument("--brand", default="")
    ap.add_argument("--language", default="ko")
    ap.add_argument("--title", default="")
    ap.add_argument("--dpi", type=int, default=300)
    ap.add_argument("--min_area", type=float, default=10000.0)
    ap.add_argument("--sleep", type=float, default=DEFAULT_PER_PAGE_SLEEP)
    args = ap.parse_args()

    ingest_one_with_figures(Path(args.pdf),
                            args.brand, args.language, args.title,
                            dpi=args.dpi, min_area=args.min_area,
                            per_page_sleep=args.sleep)

if __name__ == "__main__":
    main()